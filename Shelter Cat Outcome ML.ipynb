{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch import tensor\n",
    "import torch.nn.functional as F\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data sets\n",
    "training_data = pd.read_csv('Cats Training Data.csv')\n",
    "validation_data = pd.read_csv('Cats Validation Data.csv')\n",
    "test_data = pd.read_csv('Cats Testing Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the training & validation set so the one hot encoding will not be different if the validation set happens to not have some of the same categories\n",
    "\n",
    "fused_data = pd.concat([training_data, validation_data], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_start_index = training_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome Type                                    1\n",
       "Intake Age                              -0.542123\n",
       "Outcome Age                             -0.490138\n",
       "Duration of Stay                         1.276812\n",
       "Birth Year                               0.499208\n",
       "Birth Month                             -1.067045\n",
       "Intake Year                              0.247798\n",
       "Intake Month                             1.592974\n",
       "Outcome Year                             0.232558\n",
       "Outcome Month                            0.964325\n",
       "Sex                                        Female\n",
       "Breed                          Domestic Shorthair\n",
       "Intake Type                                 Stray\n",
       "Intake Condition                 Nursing Juvenile\n",
       "Intake Reproductive Status                 Intact\n",
       "Outcome Reproductive Status               Altered\n",
       "Breed2                               Not Provided\n",
       "Purebred?                                   False\n",
       "Coat Length                                 short\n",
       "color1                                     Calico\n",
       "color2                                Empty Color\n",
       "color3                                Empty Color\n",
       "pattern1                                   Calico\n",
       "pattern2                            Empty Pattern\n",
       "pattern3                            Empty Pattern\n",
       "Weekend Intake?                             False\n",
       "Weekend Outcome?                            False\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure that I have the index of the start of the validation data recorded correctly\n",
    "validation_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome Type                                    1\n",
       "Intake Age                              -0.542123\n",
       "Outcome Age                             -0.490138\n",
       "Duration of Stay                         1.276812\n",
       "Birth Year                               0.499208\n",
       "Birth Month                             -1.067045\n",
       "Intake Year                              0.247798\n",
       "Intake Month                             1.592974\n",
       "Outcome Year                             0.232558\n",
       "Outcome Month                            0.964325\n",
       "Sex                                        Female\n",
       "Breed                          Domestic Shorthair\n",
       "Intake Type                                 Stray\n",
       "Intake Condition                 Nursing Juvenile\n",
       "Intake Reproductive Status                 Intact\n",
       "Outcome Reproductive Status               Altered\n",
       "Breed2                               Not Provided\n",
       "Purebred?                                   False\n",
       "Coat Length                                 short\n",
       "color1                                     Calico\n",
       "color2                                Empty Color\n",
       "color3                                Empty Color\n",
       "pattern1                                   Calico\n",
       "pattern2                            Empty Pattern\n",
       "pattern3                            Empty Pattern\n",
       "Weekend Intake?                             False\n",
       "Weekend Outcome?                            False\n",
       "Name: 53198, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_data.iloc[validation_start_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for the catgeorical variables\n",
    "# Because there are so many, using embedding might be a good upgrade (fastai does by default w/ tabular pandas)\n",
    "\n",
    "fused_data = pd.get_dummies(fused_data, columns = \n",
    "        ['Sex', 'Breed', 'Intake Type', 'Intake Condition', 'Intake Reproductive Status', 'Outcome Reproductive Status', 'Breed2', 'Purebred?', 'Coat Length', 'color1', 'color2', 'color3', 'pattern1', 'pattern2', 'pattern3', 'Weekend Intake?', 'Weekend Outcome?'])\n",
    "\n",
    "#training_data = pd.get_dummies(training_data, columns = \n",
    "#        ['Sex', 'Breed', 'Intake Type', 'Intake Condition', 'Intake #Reproductive Status', 'Outcome Reproductive Status', 'Breed2', 'Purebred?', #'Coat Length', 'color1', 'color2', 'color3', 'pattern1', 'pattern2', #'pattern3', 'Weekend Intake?', 'Weekend Outcome?'])\n",
    "\n",
    "#validation_data = pd.get_dummies(validation_data, columns = \n",
    "#        ['Sex', 'Breed', 'Intake Type', 'Intake Condition', 'Intake #Reproductive Status', 'Outcome Reproductive Status', 'Breed2', 'Purebred?', #'Coat Length', 'color1', 'color2', 'color3', 'pattern1', 'pattern2', #'pattern3', 'Weekend Intake?', 'Weekend Outcome?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataframes to tensors (with extra dimension to allow for matrix multiplication and separating the targets from the features\n",
    "\n",
    "training_target = tensor(fused_data.iloc[0:validation_start_index-1, 0].values, dtype = torch.float)\n",
    "training_target = training_target[:,None]\n",
    "training_features = tensor(fused_data.iloc[0:validation_start_index-1, 1:].values.astype(np.float64), dtype = torch.float)\n",
    "\n",
    "validation_target = tensor(fused_data.iloc[validation_start_index:, 0].values, dtype = torch.float)\n",
    "validation_target = validation_target[:,None]\n",
    "validation_features = tensor(fused_data.iloc[validation_start_index:, 1:].values.astype(np.float64), dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53197, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure the size is as expected; it is. \n",
    "training_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_coeff = training_features.shape[1]\n",
    "\n",
    "def init_coeffs():\n",
    "    hiddens = [10, 10] \n",
    "    sizes = [n_coeff] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts\n",
    "\n",
    "def calc_preds(coeffs, features): \n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = features\n",
    "    for i,l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.relu(res)\n",
    "    return torch.sigmoid(res)\n",
    "\n",
    "def calc_loss(coeffs, features, targets): return torch.abs(calc_preds(coeffs, features)-targets).mean()\n",
    "\n",
    "def update_coeffs(coeffs, lr):\n",
    "    layers,consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()\n",
    "\n",
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, training_features, training_target)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")\n",
    "\n",
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(1004)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs\n",
    "\n",
    "def show_coeffs(): return dict(zip(fused_data.iloc[:, 1:].columns, coeffs))\n",
    "\n",
    "def acc(coeffs): return (validation_target.bool()==(calc_preds(coeffs, validation_features)>0.5)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.500; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.499; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.498; 0.497; 0.497; 0.497; 0.497; 0.497; 0.497; 0.496; 0.496; 0.496; 0.496; 0.495; 0.495; 0.495; 0.494; 0.494; 0.493; 0.493; 0.492; 0.491; 0.491; 0.490; 0.488; 0.487; 0.485; 0.483; 0.480; 0.477; 0.473; 0.469; 0.463; 0.456; 0.448; 0.438; 0.428; 0.417; 0.406; 0.394; 0.383; 0.372; 0.361; 0.350; 0.340; 0.331; 0.321; 0.312; 0.304; 0.295; 0.288; 0.280; 0.273; 0.266; 0.259; 0.253; 0.247; 0.241; 0.235; 0.230; 0.226; 0.221; 0.217; 0.212; 0.209; 0.205; 0.201; 0.198; 0.195; 0.192; 0.189; 0.187; 0.184; 0.182; 0.179; 0.177; 0.175; 0.173; 0.171; 0.169; 0.167; 0.165; 0.164; 0.162; 0.160; 0.159; 0.158; 0.156; 0.155; 0.153; 0.152; 0.151; 0.150; 0.149; 0.147; 0.146; 0.145; 0.144; 0.143; 0.142; 0.141; 0.141; 0.140; 0.139; 0.138; 0.137; 0.136; 0.136; 0.135; 0.134; 0.133; 0.133; 0.132; 0.131; 0.131; 0.130; 0.129; 0.129; 0.128; 0.128; 0.127; 0.127; 0.126; 0.126; 0.125; 0.124; 0.124; 0.123; 0.123; 0.123; 0.122; 0.122; 0.121; 0.121; 0.120; 0.120; 0.120; 0.119; 0.119; 0.118; 0.118; 0.118; 0.117; 0.117; 0.117; 0.116; 0.116; 0.116; 0.115; 0.115; 0.115; 0.114; 0.114; 0.114; 0.114; 0.113; 0.113; 0.113; 0.112; 0.112; 0.112; 0.112; 0.111; 0.111; 0.111; 0.111; 0.110; 0.110; 0.110; 0.110; 0.110; 0.109; 0.109; 0.109; 0.109; 0.109; 0.108; 0.108; 0.108; 0.108; 0.108; 0.108; 0.107; 0.107; 0.107; 0.107; 0.107; 0.106; 0.106; 0.106; 0.106; 0.106; 0.106; 0.106; 0.105; 0.105; 0.105; 0.105; 0.105; 0.105; 0.105; 0.104; 0.104; 0.104; 0.104; 0.104; 0.104; 0.104; 0.104; 0.104; 0.103; 0.103; 0.103; 0.103; 0.103; 0.103; 0.103; 0.103; 0.103; 0.102; 0.102; 0.102; 0.102; 0.102; 0.102; 0.102; 0.102; 0.102; 0.102; 0.102; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.101; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.100; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.099; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.098; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.097; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.096; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.095; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.094; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.093; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.092; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.091; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; 0.090; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(1000, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9073)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intake Age': tensor([[    -1.2477,     -1.7936,      0.3295,      0.7766,     -0.4428,     -0.6488,     -0.4361,  ...,     -0.5864,     -0.0173,\n",
       "               0.2356,     -0.2330,     -0.1476,     -0.3462,      0.1011],\n",
       "         [    -1.0016,     -1.7442,      0.3005,      0.6924,     -0.2996,     -0.6117,     -0.4456,  ...,     -0.6097,      0.0048,\n",
       "              -0.1030,     -0.1999,      0.0563,     -0.3633,      0.0369],\n",
       "         [     2.0246,      0.3735,     -4.2920,      2.1045,      1.1816,      0.5732,      0.1306,  ...,      0.9959,      0.0243,\n",
       "               3.8689,      0.0793,     -4.7518,      0.2797,      0.0774],\n",
       "         [     0.3038,      0.9051,     -0.0211,     -0.0358,      0.1385,      0.7228,      0.3447,  ...,      0.5660,      0.0114,\n",
       "               0.3281,      0.0919,     -0.6960,      0.3460,      0.0580],\n",
       "         [    -0.3212,     -0.0733,      0.4014,      0.6981,      0.5987,     -0.0623,      0.0064,  ...,     -0.3908,      0.0064,\n",
       "              -0.8338,     -0.0110,     -0.8568,     -0.0389,     -1.0898],\n",
       "         [    -0.8385,     -0.2652,      0.7095,      0.1110,     -0.2400,      0.4042,      0.0997,  ...,      0.2779,     -0.0049,\n",
       "               0.0062,     -0.0364,     -0.1078,      0.1608,      0.0284],\n",
       "         [    -0.9225,     -0.8855,      1.0433,     -0.0265,     -0.2473,     -0.1103,     -0.0984,  ...,      0.0675,      0.0041,\n",
       "               1.3912,     -0.0122,      0.3659,     -0.0715,      0.3771],\n",
       "         ...,\n",
       "         [    -0.2843,     -0.2722,      0.0843,      0.0075,      0.0187,     -0.1863,     -0.2414,  ...,     -0.1066,     -0.0093,\n",
       "              -0.1986,     -0.1537,      0.3118,     -0.0987,      0.0306],\n",
       "         [     0.0041,     -0.0202,      0.0031,      0.0126,      0.0245,     -0.0238,     -0.0114,  ...,     -0.0153,      0.0133,\n",
       "               0.0062,      0.0123,     -0.0275,     -0.0019,      0.0023],\n",
       "         [     0.3559,      0.1233,     -0.0742,      0.0599,      0.0278,      0.0104,      0.0033,  ...,     -0.0181,     -0.0214,\n",
       "               0.2072,     -0.0113,     -0.2214,     -0.0164,     -0.0598],\n",
       "         [    -0.4134,     -0.2436,     -0.2148,      0.3462,     -0.1273,     -0.1672,     -0.2168,  ...,     -0.2557,     -0.0067,\n",
       "               0.3337,     -0.1081,      0.3721,     -0.0869,     -0.6686],\n",
       "         [     0.5055,      0.0652,      0.1695,     -0.3200,      0.1443,     -0.0533,     -0.0647,  ...,      0.1383,     -0.0197,\n",
       "              -0.2636,     -0.0175,     -0.2521,     -0.0425,      0.7021],\n",
       "         [    -0.5171,     -0.0122,      0.1037,     -0.9512,     -0.2629,     -0.2902,     -0.2303,  ...,      0.1996,     -0.0268,\n",
       "              -1.3548,     -0.1333,      1.1927,     -0.1846,      0.3354],\n",
       "         [     0.6061,     -0.1296,     -0.1275,      1.0309,      0.2786,      0.0938,     -0.0349,  ...,     -0.3100,     -0.0174,\n",
       "               1.3800,     -0.0369,     -1.1221,      0.0574,     -0.3760]], requires_grad=True),\n",
       " 'Outcome Age': tensor([[ 4.0718],\n",
       "         [ 2.7416],\n",
       "         [-3.5897],\n",
       "         [ 1.8574],\n",
       "         [ 1.6002],\n",
       "         [-0.5093],\n",
       "         [ 0.2664],\n",
       "         [ 3.2309],\n",
       "         [ 0.2574],\n",
       "         [ 1.1716],\n",
       "         [ 0.8343],\n",
       "         [-2.8513],\n",
       "         [-1.0703],\n",
       "         [ 1.7498],\n",
       "         [ 0.0284],\n",
       "         [ 4.1104],\n",
       "         [ 0.1943],\n",
       "         [-2.4943],\n",
       "         [-0.1526],\n",
       "         [ 1.9562]], requires_grad=True),\n",
       " 'Duration of Stay': tensor(-0.6147, requires_grad=True)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
